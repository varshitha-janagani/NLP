{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SyaAu22C9E-z"
      },
      "outputs": [],
      "source": [
        "d1=\"The cat sat on the mat\"\n",
        "d2=\"Apples are red\"\n",
        "d3=\"She loves music\"\n",
        "d4=\"The car engine broke down\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Example dataset (replace with your Excel file)\n",
        "# Correctly define data as a dictionary with a 'Sentence' key and a list of sentences\n",
        "data = {\n",
        "    \"Sentence\": [d1, d2, d3, d4]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Extract sentences\n",
        "sentences = df[\"Sentence\"].astype(str).tolist()\n",
        "\n",
        "# Initialize CountVectorizer for unigrams only\n",
        "vectorizer = CountVectorizer(ngram_range=(1,1), stop_words='english')\n",
        "\n",
        "# Fit and transform\n",
        "unigram_matrix = vectorizer.fit_transform(sentences);\n",
        "\n",
        "# Get vocabulary and counts\n",
        "word_counts = unigram_matrix.toarray().sum(axis=0)\n",
        "vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print counts in desired format\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in zip(vocab, word_counts):\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "print(f\"\\nVocabulary Size = {len(vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fph4v4qd9dC4",
        "outputId": "22be2ef9-9634-4970-9fb3-f8c7ad4d833d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "apples: 1\n",
            "broke: 1\n",
            "car: 1\n",
            "cat: 1\n",
            "engine: 1\n",
            "loves: 1\n",
            "mat: 1\n",
            "music: 1\n",
            "red: 1\n",
            "sat: 1\n",
            "\n",
            "Vocabulary Size = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "data = {\n",
        "    \"Sentence\": [d1, d2, d3, d4]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Extract sentences\n",
        "sentences = df[\"Sentence\"].astype(str).tolist()\n",
        "\n",
        "# Initialize CountVectorizer for bigrams only\n",
        "vectorizer = CountVectorizer(ngram_range=(2,2), stop_words='english')\n",
        "\n",
        "# Fit and transform\n",
        "bigram_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "# Get vocabulary and counts\n",
        "bigram_counts = bigram_matrix.toarray().sum(axis=0)\n",
        "vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print counts in desired format\n",
        "print(\"Bigram Counts:\")\n",
        "for bigram, count in zip(vocab, bigram_counts):\n",
        "    print(f\"{bigram}: {count}\")\n",
        "\n",
        "print(f\"\\nVocabulary Size = {len(vocab)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zlXfcClJ_lSZ",
        "outputId": "3f50ff32-fe29-4193-8261-a36bddc29fda"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Counts:\n",
            "apples red: 1\n",
            "car engine: 1\n",
            "cat sat: 1\n",
            "engine broke: 1\n",
            "loves music: 1\n",
            "sat mat: 1\n",
            "\n",
            "Vocabulary Size = 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "docs = [\n",
        "    \"The cat sat on the mat\",\n",
        "    \"Apples are red\",\n",
        "    \"She loves music\",\n",
        "    \"The car engine broke down\"\n",
        "]\n",
        "\n",
        "# Keep stopwords so trigrams are preserved\n",
        "vectorizer = CountVectorizer(ngram_range=(3,3))\n",
        "\n",
        "trigram_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "trigram_counts = trigram_matrix.toarray().sum(axis=0)\n",
        "vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"Trigram Counts:\")\n",
        "for trigram, count in zip(vocab, trigram_counts):\n",
        "    print(f\"{trigram}: {count}\")\n",
        "\n",
        "print(f\"\\nVocabulary Size = {len(vocab)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VHBZ945AB0pP",
        "outputId": "a98802ad-fe48-4e43-e72b-6f02d8dbeafe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram Counts:\n",
            "apples are red: 1\n",
            "car engine broke: 1\n",
            "cat sat on: 1\n",
            "engine broke down: 1\n",
            "on the mat: 1\n",
            "sat on the: 1\n",
            "she loves music: 1\n",
            "the car engine: 1\n",
            "the cat sat: 1\n",
            "\n",
            "Vocabulary Size = 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Training corpus\n",
        "data = {\n",
        "    \"Sentence\": [d1, d2, d3, d4]\n",
        "}\n",
        "\n",
        "# Tokenize sentences\n",
        "tokens = [sentence.lower().split() for sentence in data[\"Sentence\"]]\n",
        "\n",
        "# Build bigram counts\n",
        "bigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "for sentence in tokens:\n",
        "    for i in range(len(sentence)-1):\n",
        "        bigram_counts[sentence[i]][sentence[i+1]] += 1\n",
        "\n",
        "# Function to predict next word\n",
        "def predict_next_word(sequence):\n",
        "    last_word = sequence.split()[-1].lower()\n",
        "    if last_word not in bigram_counts:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "    total = sum(bigram_counts[last_word].values())\n",
        "    probs = {word: count/total for word, count in bigram_counts[last_word].items()}\n",
        "    return probs\n",
        "\n",
        "# Examples\n",
        "print(\"Given sequence: 'I am', predicted next word probabilities:\", predict_next_word(\"I am\"))\n",
        "print(\"Given sequence: 'I did my', predicted next word probabilities:\", predict_next_word(\"I did my\"))\n",
        "print(\"Given sequence: 'professor I', predicted next word probabilities:\", predict_next_word(\"professor I\"))\n",
        "print(\"Given sequence: 'nonexistent word', predicted next word:\", predict_next_word(\"nonexistent word\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KNWl6E9EDdgR",
        "outputId": "9b79af5f-12d2-47b9-d12b-44d4f86350af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am', predicted next word probabilities: No bigram found starting with 'am'.\n",
            "Given sequence: 'I did my', predicted next word probabilities: No bigram found starting with 'my'.\n",
            "Given sequence: 'professor I', predicted next word probabilities: No bigram found starting with 'i'.\n",
            "Given sequence: 'nonexistent word', predicted next word: No bigram found starting with 'word'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Training corpus\n",
        "data = {\n",
        "    \"Sentence\": [d1, d2, d3, d4]\n",
        "}\n",
        "\n",
        "# Tokenize sentences\n",
        "tokens = [sentence.lower().split() for sentence in data[\"Sentence\"]]\n",
        "\n",
        "# Build bigram counts\n",
        "bigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "for sentence in tokens:\n",
        "    for i in range(len(sentence)-1):\n",
        "        bigram_counts[sentence[i]][sentence[i+1]] += 1\n",
        "\n",
        "# Function to predict next word\n",
        "def predict_next_word(sequence):\n",
        "    last_word = sequence.split()[-1].lower()\n",
        "    if last_word not in bigram_counts:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "    total = sum(bigram_counts[last_word].values())\n",
        "    probs = {word: count/total for word, count in bigram_counts[last_word].items()}\n",
        "    # Pick the most probable next word\n",
        "    predicted = max(probs, key=probs.get)\n",
        "    return probs, predicted\n",
        "\n",
        "# Examples\n",
        "seq1 = \"The cat\"\n",
        "result1 = predict_next_word(seq1)\n",
        "if isinstance(result1, tuple):\n",
        "    probs1, pred1 = result1\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word: '{pred1}'\")\n",
        "    for w, p in probs1.items():\n",
        "        print(f\"probability of {w} is {p:.1f}\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word probabilities: {result1}\")\n",
        "\n",
        "seq2 = \"Apples\"\n",
        "result2 = predict_next_word(seq2)\n",
        "if isinstance(result2, tuple):\n",
        "    probs2, pred2 = result2\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word: '{pred2}'\")\n",
        "    for w, p in probs2.items():\n",
        "        print(f\"probability of {w} is {p:.1f}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word probabilities: {result2}\")\n",
        "\n",
        "seq3 = \"The car\"\n",
        "result3 = predict_next_word(seq3)\n",
        "if isinstance(result3, tuple):\n",
        "    probs3, pred3 = result3\n",
        "    print(f\"\\nGiven sequence: '{seq3}', predicted next word: '{pred3}'\")\n",
        "    for w, p in probs3.items():\n",
        "        print(f\"probability of {w} is {p:.1f}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq3}', predicted next word probabilities: {result3}\")\n",
        "\n",
        "seq4 = \"nonexistent word\"\n",
        "result4 = predict_next_word(seq4)\n",
        "if isinstance(result4, tuple):\n",
        "    probs4, pred4 = result4\n",
        "    print(f\"\\nGiven sequence: '{seq4}', predicted next word: '{pred4}'\")\n",
        "    for w, p in probs4.items():\n",
        "        print(f\"probability of {w} is {p:.1f}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq4}', predicted next word: {result4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uDWLTZqWD4Tz",
        "outputId": "d472746f-8178-4dfd-a0d7-af32764097ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'The cat', predicted next word: 'sat'\n",
            "probability of sat is 1.0\n",
            "\n",
            "Given sequence: 'Apples', predicted next word: 'are'\n",
            "probability of are is 1.0\n",
            "\n",
            "Given sequence: 'The car', predicted next word: 'engine'\n",
            "probability of engine is 1.0\n",
            "\n",
            "Given sequence: 'nonexistent word', predicted next word: No bigram found starting with 'word'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Training corpus\n",
        "\n",
        "data = {\n",
        "    \"Sentence\": [d1, d2, d3, d4]\n",
        "}\n",
        "# Tokenize sentences\n",
        "tokens = [sentence.lower().split() for sentence in data[\"Sentence\"]]\n",
        "\n",
        "# Build trigram counts\n",
        "trigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "for sentence in tokens:\n",
        "    for i in range(len(sentence)-2):\n",
        "        prefix = (sentence[i], sentence[i+1])\n",
        "        trigram_counts[prefix][sentence[i+2]] += 1\n",
        "\n",
        "# Function to predict next word using trigram counts\n",
        "def predict_next_word(sequence):\n",
        "    words = sequence.lower().split()\n",
        "    if len(words) < 2:\n",
        "        return \"Need at least two words for trigram prediction.\"\n",
        "    prefix = (words[-2], words[-1])\n",
        "    if prefix not in trigram_counts:\n",
        "        return f\"No trigram found starting with '{' '.join(prefix)}'.\"\n",
        "    total = sum(trigram_counts[prefix].values())\n",
        "    probs = {word: count/total for word, count in trigram_counts[prefix].items()}\n",
        "    predicted = max(probs, key=probs.get)\n",
        "    return probs, predicted\n",
        "\n",
        "# Examples\n",
        "seq1 = \"She loves\"\n",
        "result1 = predict_next_word(seq1)\n",
        "if isinstance(result1, tuple):\n",
        "    probs1, pred1 = result1\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word: '{pred1}'\")\n",
        "    for w, p in probs1.items():\n",
        "        print(f\"probability of {w} is {p:.1f}\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word: {result1}\")\n",
        "\n",
        "seq2 = \"The cat\"\n",
        "result2 = predict_next_word(seq2)\n",
        "if isinstance(result2, tuple):\n",
        "    probs2, pred2 = result2\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word: '{pred2}'\")\n",
        "    for w, p in probs2.items():\n",
        "        print(f\"probability of {w} is {p:.1f}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word: {result2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "brmenediFLRP",
        "outputId": "e69a48f5-601e-4392-913a-66e817c88e27"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'She loves', predicted next word: 'music'\n",
            "probability of music is 1.0\n",
            "\n",
            "Given sequence: 'The cat', predicted next word: 'sat'\n",
            "probability of sat is 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Training corpus\n",
        "\n",
        "data = {\n",
        "    \"Sentence\": [d1, d2, d3, d4]\n",
        "}\n",
        "# Tokenize sentences\n",
        "tokens = [sentence.lower().split() for sentence in data[\"Sentence\"]]\n",
        "\n",
        "# Build trigram counts\n",
        "trigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "for sentence in tokens:\n",
        "    for i in range(len(sentence)-2):\n",
        "        prefix = (sentence[i], sentence[i+1])\n",
        "        trigram_counts[prefix][sentence[i+2]] += 1\n",
        "\n",
        "# Function to predict next word using trigram counts\n",
        "def predict_next_word(sequence):\n",
        "    words = sequence.lower().split()\n",
        "    if len(words) < 2:\n",
        "        return \"Need at least two words for trigram prediction.\"\n",
        "    prefix = (words[-2], words[-1])\n",
        "    if prefix not in trigram_counts:\n",
        "        return f\"No trigram found starting with '{' '.join(prefix)}'.\"\n",
        "    total = sum(trigram_counts[prefix].values())\n",
        "    probs = {word: count/total for word, count in trigram_counts[prefix].items()}\n",
        "    predicted = max(probs, key=probs.get)\n",
        "    return probs, predicted\n",
        "\n",
        "# Example usage\n",
        "seq1 = \"She loves\"\n",
        "# The following lines need to handle the case where predict_next_word returns a string\n",
        "# instead of a tuple (probs, pred).\n",
        "# Modified to check the return type.\n",
        "result1 = predict_next_word(seq1)\n",
        "if isinstance(result1, tuple):\n",
        "    probs1, pred1 = result1\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word: '{pred1}'\")\n",
        "    for w, p in probs1.items():\n",
        "        print(f\"probability of {w} is {p:.1f}\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word: {result1}\")\n",
        "\n",
        "seq2 = \"The car engine\"\n",
        "result2 = predict_next_word(seq2)\n",
        "if isinstance(result2, tuple):\n",
        "    probs2, pred2 = result2\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word: '{pred2}'\")\n",
        "    for w, p in probs2.items():\n",
        "        print(f\"probability of {w} is {p:.1f}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word: {result2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-t43D-dkEh8q",
        "outputId": "3c5caef4-5aa9-4180-ec62-fb8e372b44fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'She loves', predicted next word: 'music'\n",
            "probability of music is 1.0\n",
            "\n",
            "Given sequence: 'The car engine', predicted next word: 'broke'\n",
            "probability of broke is 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# Training corpus\n",
        "data = {\n",
        "    \"Sentence\": [d1, d2, d3, d4]\n",
        "}\n",
        "# Tokenize sentences\n",
        "tokens = [sentence.lower().split() for sentence in data[\"Sentence\"]]\n",
        "\n",
        "# Build bigram counts\n",
        "bigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "vocab = set()\n",
        "for sentence in tokens:\n",
        "    for i in range(len(sentence)-1):\n",
        "        bigram_counts[sentence[i]][sentence[i+1]] += 1\n",
        "        vocab.add(sentence[i])\n",
        "        vocab.add(sentence[i+1])\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Function to predict next word with Laplace smoothing\n",
        "def predict_next_word(sequence):\n",
        "    last_word = sequence.split()[-1].lower()\n",
        "    if last_word not in bigram_counts:\n",
        "        # Modified to return a string, not attempt to compute probs for non-existent word\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "    total = sum(bigram_counts[last_word].values())\n",
        "    probs = {}\n",
        "    for word in vocab:\n",
        "        count = bigram_counts[last_word].get(word, 0)\n",
        "        # Laplace smoothing: add 1 to count, add vocab_size to denominator\n",
        "        probs[word] = (count + 1) / (total + vocab_size)\n",
        "    predicted = max(probs, key=probs.get)\n",
        "    return probs, predicted\n",
        "\n",
        "# Examples\n",
        "seq1 = \"The car\"\n",
        "result1 = predict_next_word(seq1)\n",
        "if isinstance(result1, tuple):\n",
        "    probs1, pred1 = result1\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word: '{pred1}'\")\n",
        "    for w, p in probs1.items():\n",
        "        print(f\"probability of {w} is {p}\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word: {result1}\")\n",
        "\n",
        "seq2 = \"she loves music\"\n",
        "result2 = predict_next_word(seq2)\n",
        "if isinstance(result2, tuple):\n",
        "    probs2, pred2 = result2\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word: '{pred2}'\")\n",
        "    for w, p in probs2.items():\n",
        "        print(f\"probability of {w} is {p}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word: {result2}\")\n",
        "\n",
        "seq3 = \"The cat\"\n",
        "result3 = predict_next_word(seq3)\n",
        "if isinstance(result3, tuple):\n",
        "    probs3, pred3 = result3\n",
        "    print(f\"\\nGiven sequence: '{seq3}', predicted next word: '{pred3}'\")\n",
        "    for w, p in probs3.items():\n",
        "        print(f\"probability of {w} is {p}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq3}', predicted next word: {result3}\")\n",
        "\n",
        "seq4 = \"nonexistent word\"\n",
        "result4 = predict_next_word(seq4)\n",
        "if isinstance(result4, tuple):\n",
        "    probs4, pred4 = result4\n",
        "    print(f\"\\nGiven sequence: '{seq4}', predicted next word: '{pred4}'\")\n",
        "    for w, p in probs4.items():\n",
        "        print(f\"probability of {w} is {p}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq4}', predicted next word: {result4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FDtGOxcCHoTV",
        "outputId": "c4dbada4-7770-4031-819c-78744baac575"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'The car', predicted next word: 'engine'\n",
            "probability of music is 0.0625\n",
            "probability of mat is 0.0625\n",
            "probability of apples is 0.0625\n",
            "probability of cat is 0.0625\n",
            "probability of engine is 0.125\n",
            "probability of the is 0.0625\n",
            "probability of sat is 0.0625\n",
            "probability of down is 0.0625\n",
            "probability of red is 0.0625\n",
            "probability of she is 0.0625\n",
            "probability of are is 0.0625\n",
            "probability of loves is 0.0625\n",
            "probability of car is 0.0625\n",
            "probability of broke is 0.0625\n",
            "probability of on is 0.0625\n",
            "\n",
            "Given sequence: 'she loves music', predicted next word: No bigram found starting with 'music'.\n",
            "\n",
            "Given sequence: 'The cat', predicted next word: 'sat'\n",
            "probability of music is 0.0625\n",
            "probability of mat is 0.0625\n",
            "probability of apples is 0.0625\n",
            "probability of cat is 0.0625\n",
            "probability of engine is 0.0625\n",
            "probability of the is 0.0625\n",
            "probability of sat is 0.125\n",
            "probability of down is 0.0625\n",
            "probability of red is 0.0625\n",
            "probability of she is 0.0625\n",
            "probability of are is 0.0625\n",
            "probability of loves is 0.0625\n",
            "probability of car is 0.0625\n",
            "probability of broke is 0.0625\n",
            "probability of on is 0.0625\n",
            "\n",
            "Given sequence: 'nonexistent word', predicted next word: No bigram found starting with 'word'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "data = {\n",
        "    \"Sentence\": [d1, d2, d3, d4]\n",
        "}\n",
        "# Tokenize sentences\n",
        "tokens = [sentence.lower().split() for sentence in data[\"Sentence\"]]\n",
        "\n",
        "# Build bigram counts\n",
        "bigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "vocab = set()\n",
        "for sentence in tokens:\n",
        "    for i in range(len(sentence)-1):\n",
        "        bigram_counts[sentence[i]][sentence[i+1]] += 1\n",
        "        vocab.add(sentence[i])\n",
        "        vocab.add(sentence[i+1])\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Function to predict next word with Laplace smoothing\n",
        "def predict_next_word(sequence):\n",
        "    last_word = sequence.split()[-1].lower()\n",
        "    if last_word not in bigram_counts:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "    total = sum(bigram_counts[last_word].values())\n",
        "    probs = {}\n",
        "    for word in vocab:\n",
        "        count = bigram_counts[last_word].get(word, 0)\n",
        "        # Laplace smoothing: add 1 to numerator, add vocab_size to denominator\n",
        "        probs[word] = (count + 1) / (total + vocab_size)\n",
        "    predicted = max(probs, key=probs.get)\n",
        "    return probs, predicted\n",
        "\n",
        "# Example usage\n",
        "seq1 = \"The\"\n",
        "result1 = predict_next_word(seq1)\n",
        "if isinstance(result1, tuple):\n",
        "    probs1, pred1 = result1\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word: '{pred1}'\")\n",
        "    for w, p in probs1.items():\n",
        "        print(f\"probability of {w} is {p}\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word: {result1}\")\n",
        "\n",
        "seq2 = \"The cat\"\n",
        "result2 = predict_next_word(seq2)\n",
        "if isinstance(result2, tuple):\n",
        "    probs2, pred2 = result2\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word: '{pred2}'\")\n",
        "    for w, p in probs2.items():\n",
        "        print(f\"probability of {w} is {p}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word: {result2}\")\n",
        "\n",
        "seq3 = \"The car\"\n",
        "result3 = predict_next_word(seq3)\n",
        "if isinstance(result3, tuple):\n",
        "    probs3, pred3 = result3\n",
        "    print(f\"\\nGiven sequence: '{seq3}', predicted next word: '{pred3}'\")\n",
        "    for w, p in probs3.items():\n",
        "        print(f\"probability of {w} is {p}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq3}', predicted next word: {result3}\")\n",
        "\n",
        "seq4 = \"She\"\n",
        "result4 = predict_next_word(seq4)\n",
        "if isinstance(result4, tuple):\n",
        "    probs4, pred4 = result4\n",
        "    print(f\"\\nGiven sequence: '{seq4}', predicted next word: '{pred4}'\")\n",
        "    for w, p in probs4.items():\n",
        "        print(f\"probability of {w} is {p}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq4}', predicted next word: {result4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Jy0qWPtYInsL",
        "outputId": "4477f0b7-d308-487c-e962-948f330f2a62"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'The', predicted next word: 'mat'\n",
            "probability of music is 0.05555555555555555\n",
            "probability of mat is 0.1111111111111111\n",
            "probability of apples is 0.05555555555555555\n",
            "probability of cat is 0.1111111111111111\n",
            "probability of engine is 0.05555555555555555\n",
            "probability of the is 0.05555555555555555\n",
            "probability of sat is 0.05555555555555555\n",
            "probability of down is 0.05555555555555555\n",
            "probability of red is 0.05555555555555555\n",
            "probability of she is 0.05555555555555555\n",
            "probability of are is 0.05555555555555555\n",
            "probability of loves is 0.05555555555555555\n",
            "probability of car is 0.1111111111111111\n",
            "probability of broke is 0.05555555555555555\n",
            "probability of on is 0.05555555555555555\n",
            "\n",
            "Given sequence: 'The cat', predicted next word: 'sat'\n",
            "probability of music is 0.0625\n",
            "probability of mat is 0.0625\n",
            "probability of apples is 0.0625\n",
            "probability of cat is 0.0625\n",
            "probability of engine is 0.0625\n",
            "probability of the is 0.0625\n",
            "probability of sat is 0.125\n",
            "probability of down is 0.0625\n",
            "probability of red is 0.0625\n",
            "probability of she is 0.0625\n",
            "probability of are is 0.0625\n",
            "probability of loves is 0.0625\n",
            "probability of car is 0.0625\n",
            "probability of broke is 0.0625\n",
            "probability of on is 0.0625\n",
            "\n",
            "Given sequence: 'The car', predicted next word: 'engine'\n",
            "probability of music is 0.0625\n",
            "probability of mat is 0.0625\n",
            "probability of apples is 0.0625\n",
            "probability of cat is 0.0625\n",
            "probability of engine is 0.125\n",
            "probability of the is 0.0625\n",
            "probability of sat is 0.0625\n",
            "probability of down is 0.0625\n",
            "probability of red is 0.0625\n",
            "probability of she is 0.0625\n",
            "probability of are is 0.0625\n",
            "probability of loves is 0.0625\n",
            "probability of car is 0.0625\n",
            "probability of broke is 0.0625\n",
            "probability of on is 0.0625\n",
            "\n",
            "Given sequence: 'She', predicted next word: 'loves'\n",
            "probability of music is 0.0625\n",
            "probability of mat is 0.0625\n",
            "probability of apples is 0.0625\n",
            "probability of cat is 0.0625\n",
            "probability of engine is 0.0625\n",
            "probability of the is 0.0625\n",
            "probability of sat is 0.0625\n",
            "probability of down is 0.0625\n",
            "probability of red is 0.0625\n",
            "probability of she is 0.0625\n",
            "probability of are is 0.0625\n",
            "probability of loves is 0.125\n",
            "probability of car is 0.0625\n",
            "probability of broke is 0.0625\n",
            "probability of on is 0.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Training corpus\n",
        "data = {\n",
        "    \"Sentence\": [d1, d2, d3, d4]\n",
        "}\n",
        "\n",
        "# Tokenize sentences\n",
        "tokens = [sentence.lower().split() for sentence in data[\"Sentence\"]]\n",
        "\n",
        "# Build trigram counts\n",
        "trigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "vocab = set()\n",
        "for sentence in tokens:\n",
        "    for i in range(len(sentence)-2):\n",
        "        prefix = (sentence[i], sentence[i+1])\n",
        "        trigram_counts[prefix][sentence[i+2]] += 1\n",
        "        vocab.add(sentence[i])\n",
        "        vocab.add(sentence[i+1])\n",
        "        vocab.add(sentence[i+2])\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Function to predict next word with Laplace smoothing\n",
        "def predict_next_word(sequence):\n",
        "    words = sequence.lower().split()\n",
        "    if len(words) < 2:\n",
        "        return \"Need at least two words for trigram prediction.\"\n",
        "    prefix = (words[-2], words[-1])\n",
        "    if prefix not in trigram_counts:\n",
        "        return f\"No trigram found starting with '{' '.join(prefix)}'.\"\n",
        "    total = sum(trigram_counts[prefix].values())\n",
        "    probs = {}\n",
        "    for word in vocab:\n",
        "        count = trigram_counts[prefix].get(word, 0)\n",
        "        # Laplace smoothing: add 1 to numerator, add vocab_size to denominator\n",
        "        probs[word] = (count + 1) / (total + vocab_size)\n",
        "    predicted = max(probs, key=probs.get)\n",
        "    return probs, predicted\n",
        "\n",
        "# Example usage\n",
        "seq1 = \"She loves music\"\n",
        "# The following lines need to handle the case where predict_next_word returns a string\n",
        "# instead of a tuple (probs, pred).\n",
        "# Modified to check the return type.\n",
        "result1 = predict_next_word(seq1)\n",
        "if isinstance(result1, tuple):\n",
        "    probs1, pred1 = result1\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word: '{pred1}'\")\n",
        "    for w, p in probs1.items():\n",
        "        print(f\"probability of {w} is {p}\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{seq1}', predicted next word: {result1}\")\n",
        "\n",
        "seq2 = \"The cat sat\"\n",
        "result2 = predict_next_word(seq2)\n",
        "if isinstance(result2, tuple):\n",
        "    probs2, pred2 = result2\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word: '{pred2}'\")\n",
        "    for w, p in probs2.items():\n",
        "        print(f\"probability of {w} is {p}\")\n",
        "else:\n",
        "    print(f\"\\nGiven sequence: '{seq2}', predicted next word: {result2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZTciv-rtJT3o",
        "outputId": "b68fba59-dcbf-488a-fc28-a9b48ebe0fa2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'She loves music', predicted next word: No trigram found starting with 'loves music'.\n",
            "\n",
            "Given sequence: 'The cat sat', predicted next word: 'on'\n",
            "probability of music is 0.0625\n",
            "probability of mat is 0.0625\n",
            "probability of apples is 0.0625\n",
            "probability of cat is 0.0625\n",
            "probability of engine is 0.0625\n",
            "probability of the is 0.0625\n",
            "probability of sat is 0.0625\n",
            "probability of down is 0.0625\n",
            "probability of red is 0.0625\n",
            "probability of she is 0.0625\n",
            "probability of are is 0.0625\n",
            "probability of loves is 0.0625\n",
            "probability of car is 0.0625\n",
            "probability of broke is 0.0625\n",
            "probability of on is 0.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "class AddKSmoothingTrigramModel:\n",
        "    def __init__(self, corpus, k=1):\n",
        "        self.k = k\n",
        "        self.trigram_counts = defaultdict(int)\n",
        "        self.bigram_counts = defaultdict(int)\n",
        "        self.vocab = set()\n",
        "        self._train(corpus)\n",
        "\n",
        "    def _train(self, corpus):\n",
        "        tokens = corpus.lower().split() # Added .lower() for consistency\n",
        "        self.vocab.update(tokens)\n",
        "        for i in range(len(tokens) - 2):\n",
        "            bigram_prefix = (tokens[i], tokens[i+1])\n",
        "            next_word = tokens[i+2]\n",
        "            self.bigram_counts[bigram_prefix] += 1\n",
        "            self.trigram_counts[(bigram_prefix[0], bigram_prefix[1], next_word)] += 1\n",
        "\n",
        "    def predict_next_word(self, sequence):\n",
        "        tokens = sequence.lower().split() # Added .lower() for consistency\n",
        "        if len(tokens) < 2:\n",
        "            raise ValueError(\"Need at least two words for trigram prediction.\")\n",
        "\n",
        "        bigram_prefix = (tokens[-2], tokens[-1])\n",
        "        vocab_size = len(self.vocab)\n",
        "        predictions = {}\n",
        "\n",
        "        bigram_count_for_denominator = self.bigram_counts[bigram_prefix]\n",
        "\n",
        "        for word in self.vocab:\n",
        "            trigram_candidate = (bigram_prefix[0], bigram_prefix[1], word)\n",
        "            trigram_count = self.trigram_counts[trigram_candidate]\n",
        "\n",
        "            # Add-K smoothing formula:\n",
        "            prob = (trigram_count + self.k) / (bigram_count_for_denominator + self.k * vocab_size)\n",
        "            predictions[word] = prob\n",
        "\n",
        "        # Sort by probability\n",
        "        sorted_predictions = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n",
        "        return sorted_predictions\n",
        "\n",
        "# Example usage:\n",
        "# Ensure d1, d2, d3, d4 are defined by running the first cell.\n",
        "# Construct a single corpus string from the sentences\n",
        "corpus = [d1, d2, d3, d4]\n",
        "corpus_text = \" \".join(corpus)\n",
        "\n",
        "model = AddKSmoothingTrigramModel(corpus_text, k=1)\n",
        "\n",
        "sequence = \"The cat sat\"\n",
        "predictions = model.predict_next_word(sequence)\n",
        "\n",
        "print(\"Predicted next words with probabilities:\")\n",
        "for word, prob in predictions[:5]:  # top 5 predictions\n",
        "    print(f\"{word}: {prob:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qD9ca2qf0Gcp",
        "outputId": "b1b6da44-9102-4610-f8b9-8da990dab3a5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next words with probabilities:\n",
            "on: 0.125000\n",
            "music: 0.062500\n",
            "mat: 0.062500\n",
            "apples: 0.062500\n",
            "cat: 0.062500\n"
          ]
        }
      ]
    }
  ]
}